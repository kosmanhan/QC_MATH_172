# Homework Assignment 4

Due Date: 03/11/2024 6:00 PM

Please check all homework assignments into the submissions (homeworks/submissions/hw04/your_name) folder GitHub. Please create your own folder for the homework. You will be required to check-in two files:
 - A markdown (.md) file for explaining your code 
 - A SQL (.sql) file that will run without error in PostgreSQL

Almost everybody in the class should have imported the [2018 Yellow Taxi Fare](https://data.cityofnewyork.us/Transportation/2018-Yellow-Taxi-Trip-Data/t29m-gskq). We will be exploring this dataset. 
If, for any reason, you could not get the dataset imported, attempt the exercise with the  [2020 Yellow Taxi Fare](https://data.cityofnewyork.us/Transportation/2020-Yellow-Taxi-Trip-Data-January-June-/kxp8-n2sj) dataset instead.

Please indicate if you were using the 2020 dataset in your answers.

 1. Exercise 

For each column in the database run the distinct command and record in a table how many distinct records are there. Your output should look like the one below.

|column_name|distinct_records  |
|--|--|
|vendorID  |3  |
|tpep_pickup_datetime  |?  |


...
While I will accept the solution with 17 `SELECT` statements I would encourage you to 
try and achieve this with as few `SELECT` statements as possible. Can you get the distinct count for all 17 columns from a single `SELECT`?

What can you deduce from the row count obtained from hw03 and the distinct record counts obtained in this exercise?

A: 

First, a table is created in qcmath172.public <distincttaxi2018>. The table has, as dictated by the question, two columns: <column_name> & <distinct_records>. Then, an insert statement is used to populate the 17 rows below the heading columns, with the command values, and using the distinct count statement. This gives us the desired table. 

From HW3, we know that the total number of rows is 112,234,626, while from this HW, we see that the minimum number of distinct rows is 2 (store_and_fwd_flag) and the maximum number of distinct rows is 27,456,644 (tpep_dropoff_datetime). This shows the cardinalities of all the columns one by one is less than the total number of rows. 


2. Exercise

A subquery allows you to use the output from a previous query as input for another query. Here is one way of constructing a subquery:

    select count(*) as distinct_observation_count from (select distinct "vendorID", "extra" from "qcmath290"."public"."2018_Yellow_Taxi_Trip_Data") as sub_query;

The query above will return the count of a distinct combination of vendorID and extra values in the `2018_Yellow_Taxi_Trip_Data` relation. It achieves this in two steps

 1. select the distinct combination of tuples of the vendorID and extra attributes
 2. count the results from step 1

Build a sub-query that will give you the distinct record count across all 17 columns in the 
`2018_Yellow_Taxi_Trip_Data` relation.

At this point, we know three crucial facts about our dataset:

 1. row count
 2. distinct count of observations in each column (aka cardinality of each column)
 3. total number of unique observations in the dataset

What can you deduce from these 3 key facts? 
Is there any single column in the dataset that could serve as the primary key?
Is there any combination of columns that can serve as the primary key?

A: 

The number of unique rows is: 102,804,099. While we already know that none of the columns by themselves are a candidate for being the primary key (due to having a cardinality less than the total number of rows), we now know that even all the columns together cannot be used as primary key, as there are almost 10 million duplicate entries. 

3. Exercise

Use the `WHERE` clause introduced in the last class to find the answer to these questions. As a reminder, the most basic form of the where clause can be written like this:

    select * from students where f_name = 'Ronald'
This query will return every record (tuple) from the students table (relation) where comparing the value found in f_name column with the string 'Ronald' evaluates to true.

 - How many rows have a "passenger_count" equal to 5.
 - How many distinct trips have a "passenger_count" greater than 3?
 - How many rows have a tpep_pickup_datetime between '2018-04-01 00:00:00' and '2018-05-01 00:00:00'?
 - How many distinct trips occurred in June where the tip_amount was greater than equal to $5.00?
 - How many distinct trips occurred in May where the passenger_count was greater than three and tip_amount was between $2.00 and $5.00?
 - What is the sum of tip_amount in the `2018_Yellow_Taxi_Trip_Data` dataset? (Hint: use the SUM() function to find the answer)
 
 Can you assume that the answer to your previous question is equivalent to the question of "How much tip did taxi drivers collected in total in 2018?" Explain your answer.

A:

a) 5040905
b) 9415988
c) 9305349
d) 714137
e) 236514
f) 210,156,392.47816774

We can assume that the answer to the previous question is the amount of tips that were reported by the drivers in 2018. It does not include tips that were not reported (ones that were usually given in cash outside the tracking app).


Please complete exercises 1-3 before you proceed to exercise 4.

4. Exercise

Take note of the base and the database folder's size associated with the database where `2018_Yellow_Taxi_Trip_Data` is located.

|folder_name  | size |
|--|--|
|base  |  |
|databseid  |  |

 Delete all records from the `2018_Yellow_Taxi_Trip_Data` where vendorID equals 2.

Record the size of the base folder and the size of the database folder after the delete is completed.

Check if the records got deleted by selecting the count of rows in the  `2018_Yellow_Taxi_Trip_Data` where vendorID is 2.

Explain why the size of the base and database folders changed as a result of the delete statement.

A:

Base has a size of 13.3GB, while the databaseid, 16402, also has a size of 13.3GB.
Before the deletion, the number of rows where VendorID = 2 is 64,716,535. After the deletion, the number of rows where VendorID = 2 is 0, while base and databaseid, 16402, folder has a size of 13.3GB.

5. Exercise

Run the command below

    VACUUM FULL;

Inspect the size of the base and database folders. Can you explain what happened?

A:

After running the vacuum script, base has a size of 5.61GB, while the databaseid, 16402, has a size of 5.58 GB. This appears to be a case of cache, as the data appears to be deleted from the table on dBeaver, but it still remained in memory. Such a property is helpful in case we accidentally delete something, as then it could be retrieved. 

6. Exercise

Truncate the table `2018_Yellow_Taxi_Trip_Data` and re-import the `2018_Yellow_Taxi_Trip_Data`.

A:

Completed as indicated.



